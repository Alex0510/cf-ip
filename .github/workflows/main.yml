name: Fetch IP Addresses

on:
  # 每3小时运行一次
  schedule:
    - cron: '0 */3 * * *'
  # 允许手动触发
  workflow_dispatch:

jobs:
  fetch-ips:
    runs-on: ubuntu-latest
    
    # 需要写入权限
    permissions:
      contents: write
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        # 获取完整历史记录，以便后续提交
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.x'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests beautifulsoup4

    - name: Run IP fetcher script
      run: |
        cat > fetch_ips.py << 'EOF'
        import requests
        import re
        import json
        import os

        # 目标URL列表
        urls = [
            'https://ip.164746.xyz/ipTop10.html', 
            'https://cf.090227.xyz', 
            'https://ipdb.api.030101.xyz/?type=bestcf&country=true',
            'https://www.wetest.vip/page/cloudflare/address_v4.html'
        ]

        # 正则表达式用于匹配IP地址
        ip_pattern = r'\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}\b'

        # 使用集合存储IP地址实现自动去重
        unique_ips = set()

        # 处理 https://cf.090227.xyz 的特殊逻辑
        cf_url = 'https://cf.090227.xyz'
        try:
            # 添加User-Agent头以避免被某些网站阻止
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            # 发送HTTP请求获取网页内容
            response = requests.get(cf_url, headers=headers, timeout=10)
            
            # 确保请求成功
            if response.status_code == 200:
                # 尝试解析JSON数据
                try:
                    data = response.json()
                    # 提取测速大于0的IP地址
                    for item in data:
                        if 'ip' in item and 'speed' in item:
                            try:
                                speed = float(item['speed'])
                                if speed > 0:
                                    unique_ips.add(item['ip'])
                            except (ValueError, TypeError):
                                # 如果speed不是数字，跳过此项
                                continue
                    print(f'从 {cf_url} 找到 {len([item for item in data if "ip" in item and "speed" in item and float(item.get("speed", 0)) > 0])} 个测速大于0的IP地址')
                except json.JSONDecodeError:
                    # 如果不是JSON格式，回退到正则表达式匹配
                    html_content = response.text
                    ip_matches = re.findall(ip_pattern, html_content, re.IGNORECASE)
                    unique_ips.update(ip_matches)
                    print(f'从 {cf_url} 找到 {len(ip_matches)} 个IP地址（使用正则匹配）')
            else:
                print(f'请求 {cf_url} 失败，状态码: {response.status_code}')
        except requests.exceptions.RequestException as e:
            print(f'请求 {cf_url} 失败: {e}')

        # 处理其他URL（使用常规方法）
        other_urls = [url for url in urls if url != cf_url]
        for url in other_urls:
            try:
                # 添加User-Agent头以避免被某些网站阻止
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
                }
                
                # 发送HTTP请求获取网页内容
                response = requests.get(url, headers=headers, timeout=10)
                
                # 确保请求成功
                if response.status_code == 200:
                    # 获取网页的文本内容
                    html_content = response.text
                    
                    # 使用正则表达式查找IP地址
                    ip_matches = re.findall(ip_pattern, html_content, re.IGNORECASE)
                    
                    # 将找到的IP添加到集合中（自动去重）
                    unique_ips.update(ip_matches)
                    print(f'从 {url} 找到 {len(ip_matches)} 个IP地址')
                else:
                    print(f'请求 {url} 失败，状态码: {response.status_code}')
            except requests.exceptions.RequestException as e:
                print(f'请求 {url} 失败: {e}')
                continue

        # 将去重后的IP地址按数字顺序排序后写入文件
        if unique_ips:
            # 按IP地址的数字顺序排序（非字符串顺序）
            sorted_ips = sorted(unique_ips, key=lambda ip: [int(part) for part in ip.split('.')])
            
            with open('ip.txt', 'w') as file:
                for ip in sorted_ips:
                    file.write(ip + '\n')
            print(f'已保存 {len(sorted_ips)} 个唯一IP地址到ip.txt文件。')
        else:
            print('未找到有效的IP地址。')
            # 创建一个空文件，避免后续步骤出错
            with open('ip.txt', 'w') as file:
                file.write('')
        EOF
        
        python fetch_ips.py

    - name: Check for changes
      id: git-check
      run: |
        if git diff --quiet; then
          echo "changed=false" >> $GITHUB_OUTPUT
        else
          echo "changed=true" >> $GITHUB_OUTPUT
        fi

    - name: Commit and push if changed
      if: steps.git-check.outputs.changed == 'true'
      run: |
        git config --local user.email "github-actions[bot]@users.noreply.github.com"
        git config --local user.name "github-actions[bot]"
        git add ip.txt
        git commit -m "Auto-update IP addresses - $(date +'%Y-%m-%d %H:%M:%S')"
        git push